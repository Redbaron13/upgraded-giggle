{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1B_-L4w5BYBu2CdnXZGT155hPjy4LGTkv",
      "authorship_tag": "ABX9TyOAmugOlnoOWRWDUel/QngX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Redbaron13/upgraded-giggle/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "!pip install PyMuPDF==1.23.1 fuzzywuzzy==0.18.0 pandas==2.0.3 textract==1.4.5"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "I8K8iw7clDwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import os\n",
        "   os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/kmbfiles-a93d6849ab6a.json\""
      ],
      "cell_type": "code",
      "metadata": {
        "id": "9C14JVIQI2kC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import re\n",
        "from typing import List, Dict, Tuple\n",
        "import fitz  # PyMuPDF\n",
        "from fuzzywuzzy import fuzz\n",
        "import logging\n",
        "import textract  # For alternative text extraction"
      ],
      "metadata": {
        "id": "Geqy4tK9dbvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "# %%\n",
        "!pip install PyMuPDF==1.23.1 fuzzywuzzy==0.18.0 pandas==2.0.3 textract==1.4.5\n",
        "# %%\n",
        "import os\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import re\n",
        "from typing import List, Dict, Tuple\n",
        "import fitz  # PyMuPDF\n",
        "from fuzzywuzzy import fuzz\n",
        "import logging\n",
        "import textract  # For alternative text extraction\n",
        "# %%\n",
        "# --- Configuration for Local Runtime ---\n",
        "COMBOS_FOLDER = \"/content/drive/MyDrive/MakerhoodsFinDocs/Combo\"  # Update with your local path\n",
        "SPREADSHEET_PATH = \"/2makerhoods.xlsx\"  # Update with your local path\n",
        "DATABASE_NAME = \"account_data.db\"  # Keep this for the database\n",
        "\n",
        "# ... (Rest of the code remains the same) ...\n",
        "# %%\n",
        "def index_and_categorize_pdfs(combos_folder):\n",
        "    \"\"\"Indexes and categorizes PDF files.\"\"\"\n",
        "    pdf_files = []\n",
        "    tax_docs = []\n",
        "\n",
        "    try:\n",
        "        for index, filename in enumerate(os.listdir(combos_folder)):\n",
        "            if filename.endswith(\".pdf\"):\n",
        "                # ... (rest of the function logic) ...\n",
        "    except FileNotFoundError:\n",
        "        logging.error(f\"Error: The specified combos folder '{combos_folder}' was not found.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An unexpected error occurred while indexing PDFs: {e}\")\n",
        "\n",
        "\n",
        "    return pdf_files, tax_docs\n",
        "\n",
        "      for index, filename in enumerate(os.listdir(combos_folder)):\n",
        "        if filename.endswith(\".pdf\"):\n",
        "            pdf_index = str(index + 1).zfill(3)  # 3-digit index\n",
        "            if any(keyword in filename.lower() for keyword in [\"tax\", \"1099\", \"w-2\", \"w2\"]):\n",
        "                tax_docs.append((pdf_index, filename))\n",
        "            else:\n",
        "                pdf_files.append((pdf_index, filename))\n",
        "\n",
        "    return pdf_files, tax_docs\n",
        "# %%\n",
        "def match_pdfs_to_accounts(pdf_files, spreadsheet_data):\n",
        "    \"\"\"Matches PDFs to accounts based on filename and spreadsheet data.\"\"\"\n",
        "    matched_pdfs = {}  # Store matched PDFs {account_index: [(pdf_index, matched_attributes)]}\n",
        "    potential_matches = {}  # Store potential matches {attribute: [pdf_indices]}\n",
        "\n",
        "    try:\n",
        "        for pdf_index, filename in pdf_files:\n",
        "            # ... (rest of the function logic) ...\n",
        "    except KeyError as e:\n",
        "        logging.error(f\"Error: Spreadsheet is missing a required column: {e}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An unexpected error occurred during PDF matching: {e}\")\n",
        "\n",
        "    return matched_pdfs, potential_matchesfor pdf_index, filename in pdf_files:\n",
        "        filename_lower = filename.lower()\n",
        "        for index, row in spreadsheet_data.iterrows():\n",
        "            # Get relevant attributes from spreadsheet\n",
        "            account_name = str(row[\"AccountName\"]).lower()\n",
        "            bank_name = str(row[\"BankName\"]).lower()\n",
        "            account_type = str(row[\"AccountType\"]).lower()\n",
        "            account_group = str(row[\"AccountGroup\"]).lower()\n",
        "            account_number = str(row[\"AccountNumber\"]).lower()\n",
        "\n",
        "            matches = 0\n",
        "            matched_attributes = []  # Keep track of matched attributes\n",
        "\n",
        "            # Prioritize AccountNumber if available\n",
        "            if account_number and account_number in filename_lower:\n",
        "                matches += 2  # Higher weight for AccountNumber match\n",
        "                matched_attributes.append(\"AccountNumber\")\n",
        "\n",
        "            # Check for other attribute matches\n",
        "            for attribute in [account_name, bank_name, account_type, account_group]:\n",
        "                if attribute and attribute in filename_lower:\n",
        "                    matches += 1\n",
        "                    matched_attributes.append(attribute.capitalize())\n",
        "\n",
        "            # Check for date-related keywords in filename (PDFFN1-6)\n",
        "            date_keywords = [\"q42024\", \"q12025\", \"october 2024\", \"november 2024\",\n",
        "                            \"march 2025\", \"april 2025\"]\n",
        "            if any(keyword in filename_lower for keyword in date_keywords):\n",
        "                matches += 1  # Add weight for date-related keywords\n",
        "                matched_attributes.append(\"DateKeyword\")  # Indicate date keyword match\n",
        "\n",
        "            # Assign matches based on priority and update spreadsheet\n",
        "            if matches > 1:  # At least 2 attributes or AccountNumber + DateKeyword match\n",
        "                matched_pdfs.setdefault(index, []).append((pdf_index, matched_attributes))\n",
        "                logging.debug(f\"PDF {filename} matched to account {index} based on: {', '.join(matched_attributes)}\")\n",
        "            elif matches == 1:  # Single attribute match (potential match)\n",
        "                for attribute in [account_name, bank_name, account_type, account_group]:\n",
        "                    if attribute and attribute in filename_lower:\n",
        "                        potential_matches.setdefault(attribute, []).append(pdf_index)\n",
        "                        break\n",
        "\n",
        "    return matched_pdfs, potential_matches\n",
        "# %%\n",
        "# After matching is done and spreadsheet_data is updated\n",
        "   for index, row in spreadsheet_data.iterrows():\n",
        "       pdf_filenames = [row[f\"PDFFN{i}\"] for i in range(1, 7) if pd.notna(row[f\"PDFFN{i}\"])]\n",
        "       if len(pdf_filenames) != len(set(pdf_filenames)):  # Check for duplicates\n",
        "           spreadsheet_data.loc[index, \"PDFDup\"] = True\n",
        "       else:\n",
        "           spreadsheet_data.loc[index, \"PDFDup\"] = False\n",
        "# %%\n",
        "def resolve_ambiguity(account_index, potential_matches, account_data):\n",
        "    \"\"\"Resolves ambiguity when multiple PDFs match an account based on filename.\"\"\"\n",
        "    logging.warning(f\"Multiple potential matches found for account index {account_index}:\")\n",
        "\n",
        "    # Limit the number of matches displayed\n",
        "    max_matches_to_display = 10\n",
        "    displayed_matches = potential_matches[:max_matches_to_display]\n",
        "\n",
        "    for i, match in enumerate(displayed_matches):\n",
        "        pdf_index, filename = match\n",
        "        logging.warning(f\"{i+1}. PDF Index: {pdf_index}, Filename: {filename}\")\n",
        "\n",
        "    if len(potential_matches) > max_matches_to_display:\n",
        "        logging.warning(f\"   ...and {len(potential_matches) - max_matches_to_display} more potential matches.\")\n",
        "\n",
        "    while True:\n",
        "        choice = input(\"Enter the number of the correct PDF, 'n' for none, 's' to skip: \")\n",
        "        if choice.isdigit() and 1 <= int(choice) <= len(displayed_matches):\n",
        "            return displayed_matches[int(choice)-1][0]\n",
        "        elif choice.lower() == 'n':\n",
        "            return None\n",
        "        elif choice.lower() == 's':\n",
        "            return 'skip'\n",
        "        else:\n",
        "            print(\"Invalid choice. Please try again.\")\n",
        "# %%\n",
        "import re\n",
        "\n",
        "   def extract_date_from_filename(filename):\n",
        "       \"\"\"Extracts date from filename using regex.\"\"\"\n",
        "       date_patterns = [\n",
        "           r\"(\\d{2}-\\d{2}-\\d{4})\",  # MM-DD-YYYY\n",
        "           r\"(\\d{4}-\\d{2}-\\d{2})\",  # YYYY-MM-DD\n",
        "           r\"(\\w{3} \\d{2}, \\d{4})\",  # Month DD, YYYY\n",
        "           r\"(\\d{4})\"  # Year only\n",
        "       ]\n",
        "       for pattern in date_patterns:\n",
        "           match = re.search(pattern, filename, re.IGNORECASE)\n",
        "           if match:\n",
        "               return match.group(1)\n",
        "       return None  # Return None if no date found\n",
        "# %%\n",
        "def sort_matched_pdfs(matched_pdfs):\n",
        "       \"\"\"Sorts matched PDFs by date extracted from filename.\"\"\"\n",
        "       for account_index, pdf_data in matched_pdfs.items():\n",
        "           # Sort by date, handling None values (no date found)\n",
        "           matched_pdfs[account_index] = sorted(pdf_data, key=lambda x: extract_date_from_filename(x[0]) or \"\", reverse=True)\n",
        "# %%\n",
        "def assign_pdf_filenames_to_spreadsheet(matched_pdfs, spreadsheet_data):\n",
        "       \"\"\"Assigns sorted PDF filenames to PDFFN1-6 columns in spreadsheet.\"\"\"\n",
        "       for account_index, pdf_data in matched_pdfs.items():\n",
        "           for i, (pdf_index, _) in enumerate(pdf_data):  # _ ignores matched_attributes\n",
        "               column_name = f\"PDFFN{i + 1}\"\n",
        "               if column_name in spreadsheet_data.columns and i < 6:  # Assign to max 6 columns\n",
        "                   spreadsheet_data.loc[account_index, column_name] = pdf_index\n",
        "# %%"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "BiCufSrAfngZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "def main():\n",
        "    try:\n",
        "        # ... (Your existing code for indexing, matching, sorting, etc.) ...\n",
        "    except Exception as e:\n",
        "        logging.error(f\"A critical error occurred during program execution: {e}\")\n",
        ""
      ],
      "cell_type": "code",
      "metadata": {
        "id": "C4QYNb6NijW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "def main():\n",
        "    # ... (Your existing code) ...\n",
        "\n",
        "    # ... (Matching and potential matching logic) ...\n",
        "\n",
        "    # Sort matched PDFs by date\n",
        "    sort_matched_pdfs(matched_pdfs)\n",
        "\n",
        "    # Assign PDF filenames to spreadsheet\n",
        "    assign_pdf_filenames_to_spreadsheet(matched_pdfs, spreadsheet_data)\n",
        "\n",
        "    # ... (Rest of your code, including saving the updated spreadsheet) ..."
      ],
      "cell_type": "code",
      "metadata": {
        "id": "t2dH445Fi1ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# ... (After assigning PDF filenames) ...\n",
        "for attribute, pdf_indices in potential_matches.items():\n",
        "    try:\n",
        "        # 1. Extract text from PDFs\n",
        "        # ... (Your logic for text extraction) ...\n",
        "\n",
        "        # 2. Identify account numbers using regex\n",
        "        # ... (Your logic for account number identification) ...\n",
        "\n",
        "        # 3. Compare and resolve ambiguities\n",
        "        # ... (Your logic for comparison and ambiguity resolution) ...\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error processing potential matches for attribute '{attribute}': {e}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "0XspGr6ZiEMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "spreadsheet_data = pd.read_excel(SPREADSHEET_PATH)  # Load your spreadsheet\n",
        "   # ... (Your existing code for indexing, categorizing, matching, sorting, and assigning PDF filenames) ...\n",
        "   spreadsheet_data.to_excel(\"updated_spreadsheet.xlsx\", index=False)  # Save the updated spreadsheet\n",
        ""
      ],
      "cell_type": "code",
      "metadata": {
        "id": "g8l-OfDegDvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# ... (After assigning PDF filenames) ...\n",
        "   for attribute, pdf_indices in potential_matches.items():\n",
        "       # Implement logic to analyze PDFs in potential_matches:\n",
        "       # 1. Extract text from PDFs\n",
        "       # 2. Identify account numbers using regex or other techniques\n",
        "       # 3. Compare extracted account numbers with spreadsheet data\n",
        "       # 4. Resolve ambiguities (user input or heuristics)\n",
        "       # 5. Update spreadsheet with matched PDF filenames for potential matches"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "2zmmxC5NgEx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# ... (After handling potential matches) ...\n",
        "for account_index, row in spreadsheet_data.iterrows():\n",
        "    for pdf_filename in row[['PDFFN1', 'PDFFN2', 'PDFFN3', 'PDFFN4', 'PDFFN5', 'PDFFN6']].values:\n",
        "        if pd.notna(pdf_filename):\n",
        "            try:\n",
        "                # 1. Open the PDF file\n",
        "                # ... (Your logic for opening the PDF) ...\n",
        "\n",
        "                # 2. Extract data\n",
        "                # ... (Your logic for data extraction) ...\n",
        "\n",
        "                # 3. Populate spreadsheet\n",
        "                # ... (Your logic for populating the spreadsheet) ...\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Error extracting data from PDF '{pdf_filename}' for account {account_index}: {e}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "LA9wkUOmiKeP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
